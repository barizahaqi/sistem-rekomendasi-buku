# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Buku.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17yBblJmdaO9sIJ-bjS3Hhel2T1JLXtUq
"""

! pip install kaggle

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/MyDrive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Kaggle

! kaggle datasets download -d zygmunt/goodbooks-10k

! unzip \*.zip && rm *.zip

# Import library
import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
 
books = pd.read_csv('books.csv')
ratings = pd.read_csv('ratings.csv')

"""Terdapat 5 variabel pada dataset yang dipilih dan ada 2 variabel yang akan dipakai yaitu:

*   books: merupakan data seluruh buku
*   ratings: merupakan rating buku yang diberikan pengguna dalam rentang 1-5






"""

books

books['title'][2]

"""Terdapat 23 kolom pada variabel books yaitu id, book_id, best_book_id, work_id, books_count, isbn, isbn13, authors,original_publication_year, original_title, title, language_code, average_rating, ratings_count, work_text_reviews_count, ratings_1, ratings_2, ratings_3, ratings_4, ratings_5, image_url, dan small_image_url"""

print('Jumlah data buku: ', len(books.book_id.unique()))

ratings

"""Terdaapat 3 kolom pada variabel ratings yaitu book_id, user_id dan rating."""

print('Jumlah user: ', len(ratings.user_id.unique()))

# Cek missing value books
books.isnull().sum()

"""Terdapat missing value pada beberapa kolom. Ambil kolom penting yang akan dipakai dari variabel books dengan tidak ada missing value"""

books = books[['book_id', 'title']]
books

"""Pada books_dataset terdapat 2 kolom yaitu:


*   book id : Id buku
*   title : judul buku



"""

# Cek missing value ratings
ratings.isnull().sum()

"""Karena tidak ada missing value pada ratings maka tidak perlu dilakukan pembersihan missing value"""

# merge variabel book dengan ratings
books_rating = pd.merge(books, ratings, on='book_id')
books_rating

"""Setelah dilakukan merge pada variabel books dan ratings  berdasarkan book_id, jumlah data rating terhadap buku keseluruhan menjadi 79701 baris"""

print('Jumlah data buku: ', len(books_rating.book_id.unique()))
print('Jumlah user: ', len(books_rating.user_id.unique()))

# pisahkan menjadi variabel books dan ratings terpisah dan hapus duplikatnya
books = books_rating[['book_id', 'title']].drop_duplicates()
books

ratings = books_rating[['book_id', 'user_id', 'rating']].drop_duplicates()
ratings

"""Setelah dilakukan pemisahan data pada variabel book_rating dan menghapus duplikatnya, jumlah data pada variabel books berkurang menjadi 812 dan jumlah data variabel pada variabel ratings berkurang menjadi 79583"""

# Encode fitur 'user_id' ke dalam indeks integer
user_ids = ratings['user_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Endcode fitur 'book_id' ke dalam indeks integer
book_ids = ratings['book_id'].unique().tolist()
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}

# Mapping user_id ke dataframe ratings user
ratings['user'] = ratings['user_id'].map(user_to_user_encoded)
 
# Mapping book_id ke dataframe ratings book
ratings['book'] = ratings['book_id'].map(book_to_book_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
 
# Mendapatkan jumlah book
num_book = len(book_encoded_to_book)
 
# Mengubah rating menjadi nilai float
ratings['rating'] = ratings['rating'].values.astype(np.float32)
 
# mendapatkan Nilai minimum dan maksimum rating
min_rating = min(ratings['rating'])
max_rating = max(ratings['rating'])
 
print('Jumlah pengguna: {}, Jumlah buku: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""Setelah dilakukan encode ke dalam indeks integer pada kolom book_id dan user_id terdapat 2 kolom baru yaitu user dan book yang merupakan bilangan integer yang merepresentasikannya secara berurutan"""

# Mengacak dataset
ratings = ratings.sample(frac=1, random_state=42)
ratings

"""dataset diacak agar distribusinya menjadi random"""

# Membuat variabel x untuk mencocokkan data user dan book menjadi satu value
x = ratings[['user', 'book']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x)
print(y)

"""variabel x merupakan kumpulan data integer yang merepresentasikan buku dan varibel y merupakan kumpulan data hasil rating dimana nilai 0 yang berarti minimum dan nilai 1 yang berarti maksimum"""

# Membuat kelas RecommenderNet untuk Collaborative Filtering
class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_books = num_books
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.book_embedding = layers.Embedding(
        num_books,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_books, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1])
 
    dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
 
    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x)

#Inisiasi model menggunakan kelas RecommenderNet
model = RecommenderNet(num_users, num_book, 50)
 
# compile terhadap model
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 25,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Setelah dilakukan proses training, model yang dihasilkan cukup mulus dan konvergen. Dari proses ini, nilai error akhir yang dihasilkan sekitar 0.17 dan error validasi sebesar 0.23. Hal ini membuktikan bahwa model memiliki performasi bagus untuk sebuah sistem rekomendasi"""

# Cek Sistem rekomendasi pada satu user

book_df = books
ratings_df = ratings
 
# Mengambil sample user
user_id = ratings_df.user_id.sample(1).iloc[0]
book_read_by_user = ratings_df[ratings_df.user_id == user_id]
 
# Membuat data buku yang belum diberikan rating oleh sample user
book_not_read = book_df[~book_df['book_id'].isin(book_read_by_user.book_id.values)]['book_id'] 
book_not_read = list(
    set(book_not_read)
    .intersection(set(book_to_book_encoded.keys()))
)
 
book_not_read = [[book_to_book_encoded.get(x)] for x in book_not_read]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_read), book_not_read)
)

ratings_predict = model.predict(user_book_array).flatten()

top_ratings_indices = ratings_predict.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(book_not_read[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Book with high ratings from user')
print('----' * 8)
 
top_book_user = (
    book_read_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .book_id.values
)
 
book_df_rows = book_df[book_df['book_id'].isin(top_book_user)]
for row in book_df_rows.itertuples():
    print(row.title)
 
print('----' * 8)
print('Top 10 Book recommendation')
print('----' * 8)
 
recommended_book = book_df[book_df['book_id'].isin(recommended_book_ids)]
for row in recommended_book.itertuples():
    print(row.title)

"""Model telah memberikan 10 rekomendasi buku berdasarkan buku yang memiliki rating tertinggi dari user yang berarti model bekerja dengan baik."""